{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reinforcement Learning: Tabular and simple network Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook of a series on Reinforcement Learning. The framework used is OpenAI Gym, a set of out-of-the-box environments, from the simple Grid World to complex robotics tasks such as object manipulation. It also includes a very long list of Atari games.\n",
    "\n",
    "OpenAI gym (pip install gym) is a very useful tool to test, develop and compare Reinforcement Learning algorithms without going crazy modeling environments that most of the time have problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing `gym` module is enough to load all the classes needed. `gym.make(environment)` is the command to load a specific `Env` class. An `Env` class has everything that we would expect from an environment: \n",
    "* **Observation Space** and **Action Space**: are described by the class `Space`, and can be of the type `Discrete(n)` (a single action to be chosen among n alternatives) or of the type `Box(n,)` (continuous space, with high and low bounds). Refer to [OpenAI Gym documentation](https://gym.openai.com/docs/).\n",
    "\n",
    "Environments also have three fundamental methods:\n",
    "* **`s = env.reset()`**: resets the environment, returning the initial observation;\n",
    "* **`env.render()`**: renders the environment. Depending on the environment, it could print on the terminal or make a window pop out;\n",
    "* **`s', r, d, i = env.step(action)`**: this command is the equivalent of a RL agent loop. It performs action a, observes reward r and state s'. `step` returns (`observation`, `reward`, `done`, `info`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen Lake (aka GridWorld)\n",
    "`FrozenLake-v0' is a 4x4 GridWorld environment. It is a MDP 16 states, which can be S (start), F (frozen), H (hole, terminates episode) and G (goal). The actions available are 4 (up, down, left, right), but the ice can be made slippery. It that case, the agent will not always move in the direction it wants: the actual move is uniformly distributed among the chosen action and the two contiguous actions (e.g., if chosen action is DOWN, the environment will pick randomly an action between (LEFT, DOWN, RIGHT)).\n",
    "\n",
    "Reward is 0 at every step, except from stepping on G state, which rewards with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "IS_SLIPPERY = True\n",
    "\n",
    "# print(gym.envs.registry.all())    # https://gym.openai.com/envs/#classic_control\n",
    "env = gym.make('FrozenLake-v0', is_slippery=IS_SLIPPERY)\n",
    "print(env.observation_space.n)\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Episode Ended\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for ep in range(2):\n",
    "    s = env.reset()\n",
    "\n",
    "    for i in range(20):\n",
    "        plt.pause(1)\n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "\n",
    "        s1, r, d, _ = env.step(env.action_space.sample())\n",
    "        \n",
    "        if d:\n",
    "            print(\"Episode Ended\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "We are going to implement tabular Q-Learning. Remember that for each episode, action is chosen greedily (or $\\epsilon$-greedily - not necessary since Q-Learning is an off-policy method), while the action-value approximation is computed iteratively as $$Q(s,a) \\leftarrow Q(s,a) + \\alpha (r + \\gamma \\max Q(s', a') -Q(s,a))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Average Success Rate: 0.0, Exploration rate: 0.9995\n",
      "Episode 1000, Average Success Rate: 0.34165834165834164, Exploration rate: 0.606151595428677\n",
      "Episode 2000, Average Success Rate: 0.44427786106946526, Exploration rate: 0.36760355841993914\n",
      "Episode 3000, Average Success Rate: 0.4915028323892036, Exploration rate: 0.22293495089695248\n",
      "Episode 4000, Average Success Rate: 0.5161209697575606, Exploration rate: 0.1351999761510762\n",
      "Episode 5000, Average Success Rate: 0.5310937812437513, Exploration rate: 0.08199267758468616\n",
      "Episode 6000, Average Success Rate: 0.5447425429095151, Exploration rate: 0.04972485475880578\n",
      "Episode 7000, Average Success Rate: 0.5470647050421369, Exploration rate: 0.030155877983500955\n",
      "Episode 8000, Average Success Rate: 0.5458067741532309, Exploration rate: 0.018288177640071544\n",
      "Episode 9000, Average Success Rate: 0.546717031440951, Exploration rate: 0.011090953530777752\n",
      "Episode 10000, Average Success Rate: 0.5500449955004499, Exploration rate: 0.006726162258635551\n",
      "Episode 11000, Average Success Rate: 0.5533133351513498, Exploration rate: 0.004079113540954552\n",
      "Episode 12000, Average Success Rate: 0.5552037330222481, Exploration rate: 0.0024737980798242264\n",
      "Episode 13000, Average Success Rate: 0.556726405661103, Exploration rate: 0.0015002467762419717\n",
      "Episode 14000, Average Success Rate: 0.5615313191914864, Exploration rate: 0.000909831892902246\n",
      "Episode 15000, Average Success Rate: 0.563095793613759, Exploration rate: 0.0005517719394242999\n",
      "Episode 16000, Average Success Rate: 0.5659646272107993, Exploration rate: 0.00033462475377169903\n",
      "Episode 17000, Average Success Rate: 0.5670254690900536, Exploration rate: 0.0002029347957665263\n",
      "Episode 18000, Average Success Rate: 0.5679684461974335, Exploration rate: 0.0001230707856146795\n",
      "Episode 19000, Average Success Rate: 0.569601599915794, Exploration rate: 7.463687148674165e-05\n",
      "Episode 20000, Average Success Rate: 0.5657717114144293, Exploration rate: 4.5263890674830964e-05\n",
      "Episode 21000, Average Success Rate: 0.5597352507023475, Exploration rate: 2.7450504800258055e-05\n",
      "Episode 22000, Average Success Rate: 0.5535202945320667, Exploration rate: 1.6647491025511675e-05\n",
      "Episode 23000, Average Success Rate: 0.5471501239076562, Exploration rate: 1.0095951220608746e-05\n",
      "Episode 24000, Average Success Rate: 0.5421024123994833, Exploration rate: 6.122738308896529e-06\n",
      "Episode 25000, Average Success Rate: 0.5390184392624295, Exploration rate: 3.7131641764181064e-06\n",
      "Episode 26000, Average Success Rate: 0.5414022537594708, Exploration rate: 2.251866322785834e-06\n",
      "Episode 27000, Average Success Rate: 0.5430909966297545, Exploration rate: 1.3656551918446582e-06\n",
      "Episode 28000, Average Success Rate: 0.5436591550301775, Exploration rate: 8.28208177430808e-07\n",
      "Episode 29000, Average Success Rate: 0.5449467259749664, Exploration rate: 5.022708435185191e-07\n",
      "Episode 30000, Average Success Rate: 0.5467151094963502, Exploration rate: 3.046045754237684e-07\n",
      "Episode 31000, Average Success Rate: 0.5484016644624367, Exploration rate: 1.8472891382490378e-07\n",
      "Episode 32000, Average Success Rate: 0.550670291553389, Exploration rate: 1.120297407071251e-07\n",
      "Episode 33000, Average Success Rate: 0.5516499500015151, Exploration rate: 6.794097655336145e-08\n",
      "Episode 34000, Average Success Rate: 0.5529249139731185, Exploration rate: 4.1203132899251884e-08\n",
      "Episode 35000, Average Success Rate: 0.5534699008599754, Exploration rate: 2.498783866287266e-08\n",
      "Episode 36000, Average Success Rate: 0.5543734896252882, Exploration rate: 1.5153995269449287e-08\n",
      "Episode 37000, Average Success Rate: 0.5549309478122213, Exploration rate: 9.190213516453504e-09\n",
      "Episode 38000, Average Success Rate: 0.555774848030315, Exploration rate: 5.573449309983453e-09\n",
      "Episode 39000, Average Success Rate: 0.557395964206046, Exploration rate: 3.3800452138942725e-09\n",
      "Episode 40000, Average Success Rate: 0.5578110547236319, Exploration rate: 2.0498447213837586e-09\n",
      "Episode 41000, Average Success Rate: 0.5581327284700374, Exploration rate: 1.2431382173564905e-09\n",
      "Episode 42000, Average Success Rate: 0.5591533534915836, Exploration rate: 7.539071673726819e-10\n",
      "Episode 43000, Average Success Rate: 0.5603590614171764, Exploration rate: 4.572106376268779e-10\n",
      "Episode 44000, Average Success Rate: 0.5613736051453376, Exploration rate: 2.77277596242616e-10\n",
      "Episode 45000, Average Success Rate: 0.5620541765738539, Exploration rate: 1.6815633550684257e-10\n",
      "Episode 46000, Average Success Rate: 0.5624442946892458, Exploration rate: 1.0197922065924198e-10\n",
      "Episode 47000, Average Success Rate: 0.5630518499606392, Exploration rate: 6.18457901982715e-11\n",
      "Episode 48000, Average Success Rate: 0.5642382450365617, Exploration rate: 3.750667773809844e-11\n",
      "Episode 49000, Average Success Rate: 0.5650905083569723, Exploration rate: 2.274610560297906e-11\n"
     ]
    }
   ],
   "source": [
    "# Q Table initialization\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "# Set Learning Parameters\n",
    "if IS_SLIPPERY:\n",
    "    lr = 0.8\n",
    "else:\n",
    "    lr = .05\n",
    "y = 0.95\n",
    "numEpisodes = 50000\n",
    "maxEpStep = 100\n",
    "update = 1000\n",
    "eps = 1.0\n",
    "epsDecay = 1-5e-4\n",
    "rList = []\n",
    "rMean = []\n",
    "rWindow = []\n",
    "\n",
    "for i in range(numEpisodes):\n",
    "    s = env.reset()\n",
    "    rTotal = 0\n",
    "    done = False\n",
    "    j = 0\n",
    "    eps *= epsDecay\n",
    "    \n",
    "    while j < maxEpStep-1:\n",
    "        j += 1\n",
    "        # Choose action epsilon-greedily (epsilon decreases with number of episodes)\n",
    "        if IS_SLIPPERY:\n",
    "            a = np.argmax(Q[s, :] + np.random.randn(env.action_space.n)*(1./(i+1)))\n",
    "        else:\n",
    "            if np.random.uniform(0, 1, 1) < eps:\n",
    "                a = np.random.randint(0, 3, 1)[0]\n",
    "            else:\n",
    "                a = np.argmax(Q[s, :])\n",
    "         \n",
    "        s1, r, done, info = env.step(a)\n",
    "        \n",
    "        Q[s, a] = Q[s, a] + lr*(r + y*np.max(Q[s1, :]) - Q[s, a])\n",
    "        rTotal += r\n",
    "        s = s1\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    rList.append(rTotal)\n",
    "    rMean.append(np.mean(rList))\n",
    "    rWindow.append(np.mean(rList[-1000:]))\n",
    "    if i % update == 0:\n",
    "        print(\"Episode \" + str(i) + \", Average Success Rate: \" + str(rMean[i]) + \", Exploration rate: \" + str(eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent is learning to reach the goal in the environment, but due to the stochasticity of the FrozenLake environment, no optimal solution exists. But it keeps learning and refining the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99450dfb38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results.\n",
    "plt.plot(rMean)\n",
    "plt.plot(rWindow)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.76702738e-01 2.73284075e-03 2.65135246e-03 2.81821379e-03]\n",
      " [1.37336535e-04 3.07735586e-04 3.57289021e-04 4.74622981e-02]\n",
      " [3.49855713e-04 1.27687809e-04 5.69998515e-04 3.87877764e-02]\n",
      " [2.65465318e-04 1.38943691e-04 1.21413592e-04 3.70431472e-02]\n",
      " [1.80526438e-01 2.83670097e-04 8.31219301e-04 7.59692520e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [9.61990082e-03 6.61281194e-06 6.31884801e-07 1.02109872e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.91875079e-04 2.27291743e-04 5.85165124e-04 2.53167438e-01]\n",
      " [4.47987051e-04 1.46073083e-01 1.57950015e-04 0.00000000e+00]\n",
      " [6.11563731e-02 5.17113689e-05 3.15128266e-05 8.60704569e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.72288565e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.54030895e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learned Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.595\n"
     ]
    }
   ],
   "source": [
    "rList = []\n",
    "\n",
    "# evaluate learned policy over 1000 episodes\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    \n",
    "    while j < maxEpStep-1:\n",
    "        j += 1\n",
    "        # Choose action greedily with noise\n",
    "        a = np.argmax(Q[s, :])\n",
    "        s1, r, d, info = env.step(a)\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)\n",
    "    \n",
    "print(\"Accuracy: \" + str(np.sum(rList)/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning with Neural Networks (Q-Network Learning)\n",
    "In order to extend algorithms working on tabular methods to much more complex problems, it is necessary to introduce function approximation. In particular, it is necessary to define an approximator $Q_{\\phi}(s,a)$, where $\\phi$ indicate the weights of the network, for the action-value function $Q(s,a)$. This can be done with a neural network. In this case the network will be super simple, but the concept will help us develop much more complex networks in the future.\n",
    "\n",
    "\n",
    "The network has just one fully connected layer, connecying the input $s$ (a one-hot vector encoding of the state, 16-dimensional) and the output, a 4-dimensional vector representing $Q_{\\phi}(s, a)$. This generates a network with 16$\\times$4 weights, which replace the tabular entries.\n",
    "\n",
    "The update of the network is not the standard Q-Learning anymore, but it is based on backpropagation of the loss function, which is chosen as the squared error: $$L = \\sum_a (Q_{\\phi}(s,a))^2-y(s,a)),$$\n",
    "\n",
    "where $y(s,a)$ is the target, defined in such a way that by minimizing $L$, $Q_{\\phi}(s,a)$ will approach $$y(s,a)=r(s,a)+\\gamma\\max_{a'} Q_{\\phi}(s',a'),$$\n",
    "\n",
    "which is the goal of Q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/federico/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "    \n",
    "tf.reset_default_graph() \n",
    "\n",
    "class Qnet():\n",
    "    def __init__(self):\n",
    "        self.inputs1 = tf.placeholder(shape=[None, 16], dtype=tf.float32)\n",
    "        self.W = tf.Variable(tf.random_uniform([16,4], 0, 0.01))\n",
    "        self.Qout = tf.matmul(self.inputs1, self.W)\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "        self.targetQ = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "        self.loss = tf.reduce_sum(tf.square(self.targetQ - self.Qout))\n",
    "        self.updateModel = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(self.loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, average reward: 0.0\n",
      "Episode: 1000, average reward: 0.32967032967032966\n",
      "Episode: 2000, average reward: 0.42278860569715143\n",
      "Episode: 3000, average reward: 0.48817060979673443\n",
      "Episode: 4000, average reward: 0.5266183454136466\n",
      "Episode: 5000, average reward: 0.5576884623075385\n",
      "Episode: 6000, average reward: 0.5762372937843693\n",
      "Episode: 7000, average reward: 0.5924867876017712\n",
      "Episode: 8000, average reward: 0.6011748531433571\n",
      "Episode: 9000, average reward: 0.6093767359182313\n",
      "Episode: 10000, average reward: 0.6166383361663834\n",
      "Episode: 11000, average reward: 0.6233978729206435\n",
      "Episode: 12000, average reward: 0.6287809349220899\n",
      "Episode: 13000, average reward: 0.6350280747634798\n",
      "Episode: 14000, average reward: 0.6387400899935719\n",
      "Episode: 15000, average reward: 0.6424905006332912\n",
      "Episode: 16000, average reward: 0.6453971626773327\n",
      "Episode: 17000, average reward: 0.6496676666078466\n",
      "Episode: 18000, average reward: 0.6516304649741681\n",
      "Episode: 19000, average reward: 0.6532287774327667\n",
      "Episode: 20000, average reward: 0.655567221638918\n",
      "Episode: 21000, average reward: 0.6581115184991191\n",
      "Episode: 22000, average reward: 0.6590609517749193\n",
      "Episode: 23000, average reward: 0.660058258336594\n",
      "Episode: 24000, average reward: 0.6617640931627848\n",
      "Episode: 25000, average reward: 0.6638934442622295\n",
      "Episode: 26000, average reward: 0.6649359640013845\n",
      "Episode: 27000, average reward: 0.6663827265656828\n",
      "Episode: 28000, average reward: 0.6674047355451591\n",
      "Episode: 29000, average reward: 0.6696320816523568\n",
      "Episode: 30000, average reward: 0.6713442885237159\n",
      "Episode: 31000, average reward: 0.6727202348311345\n",
      "Episode: 32000, average reward: 0.6747289147214149\n",
      "Episode: 33000, average reward: 0.6754037756431623\n",
      "Episode: 34000, average reward: 0.6771271433193141\n",
      "Episode: 35000, average reward: 0.6790377417788063\n",
      "Episode: 36000, average reward: 0.6801755506791478\n",
      "Episode: 37000, average reward: 0.6815491473203427\n",
      "Episode: 38000, average reward: 0.6826662456251151\n",
      "Episode: 39000, average reward: 0.683341452783262\n",
      "Episode: 40000, average reward: 0.6846828829279268\n",
      "Episode: 41000, average reward: 0.6854466964220385\n",
      "Episode: 42000, average reward: 0.6859836670555463\n",
      "Episode: 43000, average reward: 0.6867747261691589\n",
      "Episode: 44000, average reward: 0.6866434853753324\n",
      "Episode: 45000, average reward: 0.6872291726850515\n",
      "Episode: 46000, average reward: 0.6877024412512771\n",
      "Episode: 47000, average reward: 0.688495989447033\n",
      "Episode: 48000, average reward: 0.6891731422262036\n",
      "Episode: 49000, average reward: 0.6895165404787658\n",
      "Rate of successful episodes: 0.69034\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "\n",
    "DQN = Qnet()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "y = 0.99\n",
    "e = 0.1\n",
    "# num_episodes = 2000\n",
    "\n",
    "jList = []\n",
    "rList_net = []\n",
    "meanReward_net = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#     print(sess.run(DQN.Qout, feed_dict={DQN.inputs1: np.identity(16)[0:1]}))\n",
    "    for i in range(numEpisodes):\n",
    "        s = env.reset()\n",
    "        totalReward = 0\n",
    "        done = False\n",
    "        j = 1\n",
    "        while j < 99:\n",
    "            j += 1\n",
    "            \n",
    "            # e-greedy action\n",
    "            a, allQ = sess.run([DQN.predict, DQN.Qout], feed_dict={DQN.inputs1: np.identity(16)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "                \n",
    "            s1, r, done, info = env.step(a[0])\n",
    "            Q1 = sess.run(DQN.Qout, feed_dict={DQN.inputs1: np.identity(16)[s1:s1+1]})\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0, a[0]] = r + y*maxQ1\n",
    "            _ = sess.run(DQN.updateModel, feed_dict={DQN.inputs1: np.identity(16)[s:s+1], DQN.targetQ: targetQ})\n",
    "            totalReward += r\n",
    "            \n",
    "            s = s1\n",
    "            if done:\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "\n",
    "        jList.append(j)\n",
    "        rList_net.append(totalReward)\n",
    "        meanReward_net.append(np.sum(rList_net)/(i+1))\n",
    "        if i % update == 0:\n",
    "            print(\"Episode: \" + str(i) + \", average reward: \" + str(meanReward_net[i]))\n",
    "#             print(Q1)\n",
    "\n",
    "print(\"Rate of successful episodes: \" + str(sum(rList_net)/numEpisodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rMean, 'r', label=\"Tabular\")\n",
    "plt.plot(meanReward_net, 'b', label=\"DQN\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After about 1000 episodes the network starts to learn the correct path. Even if the network is the simplest network possible and there is no Experience Replay, Batch Training and target networks, it converges to a solution really close to the one found with the tabular solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
