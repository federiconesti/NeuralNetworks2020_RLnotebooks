{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: Deep Deterministic Policy Gradients (DDPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDPG is an Actor-Critic algorithm. The critic $Q_{\\phi}(s,a)$ is trained as in the DQN algorithm, with gradient descent on the loss $$J(\\phi)=\\frac{1}{2}\\sum_i \\|\\underbrace{r(s_i,a_i) + \\gamma\\max_{a'}Q_{\\phi'}(s',\\mu_{\\theta'}(s'))}_{target}-Q_{\\phi}(s,a)\\|^2,$$ where $\\mu_{\\theta}(s)$ is the actor output and $\\theta', \\phi'$ are the parameters of the target actor and critic network respectively.\n",
    "\n",
    "The actor is designed to output a continuous-valued action, and it is trained to approximate $$\\mu_{\\theta}(s)\\approx\\arg\\max_{a}Q_{\\phi}(s,a)$$ by solving $$\\theta \\leftarrow \\arg\\max_{\\theta}Q_{\\phi}(s,\\mu_{\\theta}(s))$$.\n",
    "\n",
    "The actor loss function is then $L(\\theta)=Q_{\\phi}(s,a)$, whose gradient can be approximated by\n",
    "$$\\nabla_{\\theta}\\mu_{\\theta}(s)\\approx\\sum_i\\frac{d\\mu_{\\theta}(s_i)}{d\\mu}\\frac{dQ_\\phi(s_i, \\mu_{\\theta}(s_i)}{d\\phi}$$.\n",
    "\n",
    "DDPG is a very high-variance algorithm, meaning that a single optimization step could result in catastrophic forgetting (i.e., completely different performance on the same task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, state_size, action_size, max_action, H=64, lr=0.001):\n",
    "        self.H = H\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.max_action = max_action\n",
    "        self.learning_rate = lr\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('actor'):\n",
    "            c_names = ['actor_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            with tf.name_scope(\"inputs\"):\n",
    "                self.s = tf.placeholder(shape=(None, self.state_size), dtype=tf.float32)\n",
    "\n",
    "            with tf.variable_scope(\"layer1\"):\n",
    "                self.W1 = tf.get_variable(\"W1\", shape=[self.state_size, self.H],\n",
    "                                          initializer=tf.contrib.layers.xavier_initializer(), collections=c_names) #tf.initializers.random_uniform(minval=-1, maxval=1)\n",
    "                self.B1 = tf.Variable(tf.zeros([self.H]), name=\"B1\", collections=c_names)\n",
    "                self.layer1 = tf.nn.relu(tf.matmul(self.s, self.W1) + self.B1)\n",
    "            with tf.variable_scope(\"layer2\"):\n",
    "                self.W2 = tf.get_variable(\"W2\", shape=[self.H, self.H],\n",
    "                                          initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B2 = tf.Variable(tf.zeros([self.H]), name=\"B2\", collections=c_names)\n",
    "                self.layer2 = tf.nn.relu(tf.matmul(self.layer1, self.W2) + self.B2)\n",
    "            with tf.variable_scope(\"layer3\"):\n",
    "                self.W3 = tf.get_variable(\"W3\", shape=[self.H, self.action_size], initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B3 = tf.Variable(tf.zeros([self.action_size]), name=\"B3\", collections=c_names)\n",
    "                # tanh output required because of the assumption of continuous but limited action space.\n",
    "                self.output = tf.nn.tanh(tf.matmul(self.layer2, self.W3) + self.B3) * self.max_action\n",
    "        \n",
    "        # Compute gradient for actor. See formula above.\n",
    "        self.e_params = tf.get_collection('actor_params')\n",
    "        self.gradPrev = tf.placeholder(shape=(None, self.action_size), dtype=tf.float32)\n",
    "        self.grad_theta_a = tf.gradients(ys=self.output, xs=self.e_params, grad_ys=self.gradPrev)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=-self.learning_rate).apply_gradients(zip(self.grad_theta_a, self.e_params))\n",
    "\n",
    "        # TARGET NETWORK\n",
    "        with tf.variable_scope('actor_target'):\n",
    "            c_names = ['actor_target_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            with tf.name_scope(\"inputs_\"):\n",
    "                self.s_ = tf.placeholder(shape=(None, self.state_size), dtype=tf.float32)\n",
    "\n",
    "            with tf.variable_scope(\"layer1_\"):\n",
    "                self.W1_ = tf.get_variable(\"W1_\", shape=[self.state_size, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B1_ = tf.Variable(tf.zeros([self.H]), name=\"B1_\", collections=c_names)\n",
    "                self.layer1_ = tf.nn.relu(tf.matmul(self.s_, self.W1_) + self.B1_)\n",
    "            with tf.variable_scope(\"layer2_\"):\n",
    "                self.W2_ = tf.get_variable(\"W2_\", shape=[self.H, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B2_ = tf.Variable(tf.zeros([self.H]), name=\"B2_\", collections=c_names)\n",
    "                self.layer2_ = tf.nn.relu(tf.matmul(self.layer1_, self.W2_) + self.B2_)\n",
    "            with tf.variable_scope(\"layer3_\"):\n",
    "                self.W3_ = tf.get_variable(\"W3_\", shape=[self.H, self.action_size],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B3_ = tf.Variable(tf.zeros([self.action_size]), name=\"B3_\", collections=c_names)\n",
    "                self.output_ = tf.nn.tanh(tf.matmul(self.layer2_, self.W3_) + self.B3_) * self.max_action\n",
    "\n",
    "class Critic():\n",
    "    def __init__(self, state_size, action_size, H=64, lr=0.001):\n",
    "        self.H = H\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = lr\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope('critic'):\n",
    "            c_names = ['critic_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            with tf.name_scope(\"c_inputs\"):\n",
    "                self.s = tf.placeholder(shape=(None, self.state_size), dtype=tf.float32)\n",
    "                self.a = tf.placeholder(shape=(None, self.action_size), dtype=tf.float32)\n",
    "\n",
    "            with tf.variable_scope(\"c_layer1\"):\n",
    "                self.W1s = tf.get_variable(\"c_W1s\", shape=[self.state_size, self.H],\n",
    "                                          initializer=tf.contrib.layers.xavier_initializer(), collections=c_names) #tf.initializers.random_uniform(minval=-1, maxval=1)\n",
    "                self.W1a = tf.get_variable(\"c_W1a\", shape=[self.action_size, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B1 = tf.Variable(tf.zeros([self.H]), name=\"B1\", collections=c_names)\n",
    "                self.layer1 = tf.nn.sigmoid(tf.matmul(self.s, self.W1s) + tf.matmul(self.a, self.W1a) + self.B1)\n",
    "            with tf.variable_scope(\"c_layer2\"):\n",
    "                self.W2 = tf.get_variable(\"c_W2\", shape=[self.H, self.H],\n",
    "                                          initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B2 = tf.Variable(tf.zeros([self.H]), name=\"c_B2\", collections=c_names)\n",
    "                self.layer2 = tf.nn.sigmoid(tf.matmul(self.layer1, self.W2) + self.B2)\n",
    "            with tf.variable_scope(\"c_layer3\"):\n",
    "                self.W3 = tf.get_variable(\"c_W3\", shape=[self.H, 1], initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B3 = tf.Variable(tf.zeros([1]), name=\"c_B3\", collections=c_names)\n",
    "                self.output = tf.matmul(self.layer2, self.W3) + self.B3\n",
    "        \n",
    "        # Compute critic loss and gradient (used to compute actor loss)\n",
    "        self.q_target = tf.placeholder(shape=(None, 1), dtype=tf.float32)\n",
    "        self.grad_a_Q = tf.gradients(ys=self.output, xs=self.a)\n",
    "        self.loss = tf.losses.mean_squared_error(labels=self.q_target, predictions=self.output)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        # TARGET NETWORK\n",
    "        with tf.variable_scope('critic_target'):\n",
    "            c_names = ['critic_target_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            with tf.name_scope(\"c_inputs_\"):\n",
    "                self.s_ = tf.placeholder(shape=(None, self.state_size), dtype=tf.float32)\n",
    "                self.a_ = tf.placeholder(shape=(None, self.action_size), dtype=tf.float32)\n",
    "            with tf.variable_scope(\"c_layer1_\"):\n",
    "                self.W1s_ = tf.get_variable(\"c_W1s_\", shape=[self.state_size, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.W1a_ = tf.get_variable(\"c_W1a_\", shape=[self.action_size, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B1_ = tf.Variable(tf.zeros([self.H]), name=\"c_B1_\", collections=c_names)\n",
    "                self.layer1_ = tf.nn.sigmoid(tf.matmul(self.s_, self.W1s_) + tf.matmul(self.a_, self.W1a_) + self.B1_)\n",
    "            with tf.variable_scope(\"c_layer2_\"):\n",
    "                self.W2_ = tf.get_variable(\"c_W2_\", shape=[self.H, self.H],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B2_ = tf.Variable(tf.zeros([self.H]), name=\"c_B2_\", collections=c_names)\n",
    "                self.layer2_ = tf.nn.sigmoid(tf.matmul(self.layer1_, self.W2_) + self.B2_)\n",
    "            with tf.variable_scope(\"c_layer3_\"):\n",
    "                self.W3_ = tf.get_variable(\"c_W3_\", shape=[self.H, 1],\n",
    "                                           initializer=tf.contrib.layers.xavier_initializer(), collections=c_names)\n",
    "                self.B3_ = tf.Variable(tf.zeros([1]), name=\"c_B3_\", collections=c_names)\n",
    "                self.output_ = tf.matmul(self.layer2_, self.W3_) + self.B3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "import random\n",
    "\n",
    "class DDPG:\n",
    "    def __init__(self, state_size, action_size, max_action=1.,\n",
    "                 lr_a=0.0001, lr_c=0.0001,\n",
    "                 gamma=0.95, sigma=0.1, eps=1., eps_min=0.01, eps_decay=0.999,\n",
    "                 mem_size=100000, batch_size=32, H=64, name=\"cartpole\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.max_action = max_action\n",
    "        self.H = H\n",
    "        self.sigma = sigma\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=mem_size)\n",
    "        self.gamma = gamma    # discount rate\n",
    "        self.epsilon = eps  # exploration rate\n",
    "        self.epsilon_min = eps_min\n",
    "        self.epsilon_decay = eps_decay\n",
    "        self.lr_a = lr_a\n",
    "        self.lr_c = lr_c\n",
    "        self.polyak = 0.9\n",
    "\n",
    "        self.actor = Actor(self.state_size, self.action_size, self.max_action, self.H, self.lr_a)\n",
    "        self.critic = Critic(self.state_size, self.action_size, self.H, self.lr_c)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        tf.summary.FileWriter(\"logs/\", self.sess.graph)\n",
    "        self.name = name\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.update_target(tau=0)\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # epsilon-greedy + add sigma noise\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            act_values = np.random.randn(self.action_size) * 0.5*self.max_action\n",
    "        else:\n",
    "            act_values = self.sess.run(self.actor.output, feed_dict={self.actor.s: state})[0]\n",
    "        actions = np.clip(act_values + self.sigma * np.random.randn(self.action_size), -self.max_action, self.max_action)\n",
    "        return actions\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        states = np.array([item[0] for item in minibatch]).reshape(-1, self.state_size)\n",
    "        actions = np.array([item[1] for item in minibatch]).reshape(-1, self.action_size)\n",
    "        rewards = np.array([item[2] for item in minibatch]).reshape(-1, 1)\n",
    "        next_states = np.array([item[3] for item in minibatch]).reshape(-1, self.state_size)\n",
    "        dones = np.array([item[4] for item in minibatch]).reshape(-1, 1)\n",
    "\n",
    "        next_actions = self.sess.run(self.actor.output_, feed_dict={self.actor.s_: next_states})\n",
    "        targets = rewards + (1 - dones)*self.gamma * self.sess.run(self.critic.output_,\n",
    "                                                                   feed_dict={self.critic.s_: next_states, self.critic.a_: next_actions})\n",
    "\n",
    "        _, l = self.sess.run([self.critic.optimizer, self.critic.loss],\n",
    "                             feed_dict={self.critic.s: states, self.critic.a: actions, self.critic.q_target: targets})\n",
    "\n",
    "        grad_J_a = self.sess.run(self.critic.grad_a_Q, feed_dict={self.critic.s: states, self.critic.a: actions})[0]\n",
    "\n",
    "        _ = self.sess.run(self.actor.optimizer, feed_dict={self.actor.s: states, self.actor.gradPrev: grad_J_a})\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def update_target(self, tau):\n",
    "        t_params = tf.get_collection('critic_target_params')\n",
    "        e_params = tf.get_collection('critic_params')\n",
    "        replace_target_op = [tf.assign(t, t * tau + (1 - tau) * e) for t, e in zip(t_params, e_params)]\n",
    "        self.sess.run(replace_target_op)\n",
    "\n",
    "        t_params = tf.get_collection('actor_target_params')\n",
    "        e_params = tf.get_collection('actor_params')\n",
    "        replace_target_op = [tf.assign(t, t * tau + (1 - tau) * e) for t, e in zip(t_params, e_params)]\n",
    "        self.sess.run(replace_target_op)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.saver.restore(self.sess, str(self.name) + \"/\" + str(name) + \".ckpt\")\n",
    "\n",
    "    def save(self, name):\n",
    "        self.saver.save(self.sess, str(self.name) + \"/\" + str(name) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/federico/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Creating window glfw\n",
      "episode: 0/500, score: 4.0, e: 1.0, mean reward: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federico/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/federico/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/500, score: 3.0, e: 1.0, mean reward: 4.0\n",
      "episode: 2/500, score: 14.0, e: 1.0, mean reward: 3.5\n",
      "episode: 3/500, score: 6.0, e: 1.0, mean reward: 7.0\n",
      "episode: 4/500, score: 7.0, e: 1.0, mean reward: 6.75\n",
      "episode: 5/500, score: 2.0, e: 1.0, mean reward: 6.8\n",
      "episode: 6/500, score: 6.0, e: 0.99, mean reward: 6.0\n",
      "episode: 7/500, score: 4.0, e: 0.99, mean reward: 6.0\n",
      "episode: 8/500, score: 14.0, e: 0.98, mean reward: 5.75\n",
      "episode: 9/500, score: 6.0, e: 0.97, mean reward: 6.666666666666667\n",
      "episode: 10/500, score: 5.0, e: 0.97, mean reward: 6.6\n",
      "episode: 11/500, score: 3.0, e: 0.97, mean reward: 6.7\n",
      "episode: 12/500, score: 3.0, e: 0.96, mean reward: 6.7\n",
      "episode: 13/500, score: 3.0, e: 0.96, mean reward: 5.6\n",
      "episode: 14/500, score: 4.0, e: 0.96, mean reward: 5.3\n",
      "episode: 15/500, score: 11.0, e: 0.95, mean reward: 5.0\n",
      "episode: 16/500, score: 3.0, e: 0.95, mean reward: 5.9\n",
      "episode: 17/500, score: 8.0, e: 0.94, mean reward: 5.6\n",
      "episode: 18/500, score: 5.0, e: 0.94, mean reward: 6.0\n",
      "episode: 19/500, score: 4.0, e: 0.94, mean reward: 5.1\n",
      "episode: 20/500, score: 4.0, e: 0.93, mean reward: 4.9\n",
      "episode: 21/500, score: 10.0, e: 0.92, mean reward: 4.8\n",
      "episode: 22/500, score: 5.0, e: 0.92, mean reward: 5.5\n",
      "episode: 23/500, score: 10.0, e: 0.91, mean reward: 5.7\n",
      "episode: 24/500, score: 12.0, e: 0.9, mean reward: 6.4\n",
      "episode: 25/500, score: 4.0, e: 0.9, mean reward: 7.2\n",
      "episode: 26/500, score: 6.0, e: 0.89, mean reward: 6.5\n",
      "episode: 27/500, score: 4.0, e: 0.89, mean reward: 6.8\n",
      "episode: 28/500, score: 16.0, e: 0.88, mean reward: 6.4\n",
      "episode: 29/500, score: 4.0, e: 0.88, mean reward: 7.5\n",
      "episode: 30/500, score: 11.0, e: 0.87, mean reward: 7.5\n",
      "episode: 31/500, score: 3.0, e: 0.87, mean reward: 8.2\n",
      "episode: 32/500, score: 14.0, e: 0.85, mean reward: 7.5\n",
      "episode: 33/500, score: 5.0, e: 0.85, mean reward: 8.4\n",
      "episode: 34/500, score: 4.0, e: 0.85, mean reward: 7.9\n",
      "episode: 35/500, score: 11.0, e: 0.84, mean reward: 7.1\n",
      "episode: 36/500, score: 4.0, e: 0.84, mean reward: 7.8\n",
      "episode: 37/500, score: 3.0, e: 0.84, mean reward: 7.6\n",
      "episode: 38/500, score: 5.0, e: 0.83, mean reward: 7.5\n",
      "episode: 39/500, score: 11.0, e: 0.82, mean reward: 6.4\n",
      "episode: 40/500, score: 13.0, e: 0.81, mean reward: 7.1\n",
      "episode: 41/500, score: 4.0, e: 0.81, mean reward: 7.3\n",
      "episode: 42/500, score: 3.0, e: 0.81, mean reward: 7.4\n",
      "episode: 43/500, score: 3.0, e: 0.81, mean reward: 6.3\n",
      "episode: 44/500, score: 3.0, e: 0.81, mean reward: 6.1\n",
      "episode: 45/500, score: 3.0, e: 0.81, mean reward: 6.0\n",
      "episode: 46/500, score: 9.0, e: 0.8, mean reward: 5.2\n",
      "episode: 47/500, score: 5.0, e: 0.8, mean reward: 5.7\n",
      "episode: 48/500, score: 3.0, e: 0.79, mean reward: 5.9\n",
      "episode: 49/500, score: 5.0, e: 0.79, mean reward: 5.7\n",
      "episode: 50/500, score: 6.0, e: 0.79, mean reward: 5.1\n",
      "episode: 51/500, score: 4.0, e: 0.78, mean reward: 4.4\n",
      "episode: 52/500, score: 8.0, e: 0.78, mean reward: 4.4\n",
      "episode: 53/500, score: 3.0, e: 0.78, mean reward: 4.9\n",
      "episode: 54/500, score: 8.0, e: 0.77, mean reward: 4.9\n",
      "episode: 55/500, score: 3.0, e: 0.77, mean reward: 5.4\n",
      "episode: 56/500, score: 3.0, e: 0.77, mean reward: 5.4\n",
      "episode: 57/500, score: 6.0, e: 0.77, mean reward: 4.8\n",
      "episode: 58/500, score: 6.0, e: 0.76, mean reward: 4.9\n",
      "episode: 59/500, score: 10.0, e: 0.75, mean reward: 5.2\n",
      "episode: 60/500, score: 12.0, e: 0.75, mean reward: 5.7\n",
      "episode: 61/500, score: 4.0, e: 0.74, mean reward: 6.3\n",
      "episode: 62/500, score: 12.0, e: 0.74, mean reward: 6.3\n",
      "episode: 63/500, score: 6.0, e: 0.73, mean reward: 6.7\n",
      "episode: 64/500, score: 8.0, e: 0.73, mean reward: 7.0\n",
      "episode: 65/500, score: 4.0, e: 0.73, mean reward: 7.0\n",
      "episode: 66/500, score: 9.0, e: 0.72, mean reward: 7.1\n",
      "episode: 67/500, score: 7.0, e: 0.72, mean reward: 7.7\n",
      "episode: 68/500, score: 3.0, e: 0.71, mean reward: 7.8\n",
      "episode: 69/500, score: 6.0, e: 0.71, mean reward: 7.5\n",
      "episode: 70/500, score: 12.0, e: 0.7, mean reward: 7.1\n",
      "episode: 71/500, score: 6.0, e: 0.7, mean reward: 7.1\n",
      "episode: 72/500, score: 4.0, e: 0.7, mean reward: 7.3\n",
      "episode: 73/500, score: 9.0, e: 0.69, mean reward: 6.5\n",
      "episode: 74/500, score: 8.0, e: 0.69, mean reward: 6.8\n",
      "episode: 75/500, score: 5.0, e: 0.68, mean reward: 6.8\n",
      "episode: 76/500, score: 4.0, e: 0.68, mean reward: 6.9\n",
      "episode: 77/500, score: 4.0, e: 0.68, mean reward: 6.4\n",
      "episode: 78/500, score: 4.0, e: 0.68, mean reward: 6.1\n",
      "episode: 79/500, score: 3.0, e: 0.68, mean reward: 6.2\n",
      "episode: 80/500, score: 3.0, e: 0.67, mean reward: 5.9\n",
      "episode: 81/500, score: 7.0, e: 0.67, mean reward: 5.0\n",
      "episode: 82/500, score: 4.0, e: 0.67, mean reward: 5.1\n",
      "episode: 83/500, score: 3.0, e: 0.67, mean reward: 5.1\n",
      "episode: 84/500, score: 4.0, e: 0.67, mean reward: 4.5\n",
      "episode: 85/500, score: 2.0, e: 0.66, mean reward: 4.1\n",
      "episode: 86/500, score: 3.0, e: 0.66, mean reward: 3.8\n",
      "episode: 87/500, score: 9.0, e: 0.66, mean reward: 3.7\n",
      "episode: 88/500, score: 5.0, e: 0.66, mean reward: 4.2\n",
      "episode: 89/500, score: 7.0, e: 0.65, mean reward: 4.3\n",
      "episode: 90/500, score: 6.0, e: 0.65, mean reward: 4.7\n",
      "episode: 91/500, score: 8.0, e: 0.64, mean reward: 5.0\n",
      "episode: 92/500, score: 10.0, e: 0.64, mean reward: 5.1\n",
      "episode: 93/500, score: 19.0, e: 0.63, mean reward: 5.7\n",
      "episode: 94/500, score: 3.0, e: 0.63, mean reward: 7.3\n",
      "episode: 95/500, score: 8.0, e: 0.62, mean reward: 7.2\n",
      "episode: 96/500, score: 4.0, e: 0.62, mean reward: 7.8\n",
      "episode: 97/500, score: 6.0, e: 0.62, mean reward: 7.9\n",
      "episode: 98/500, score: 7.0, e: 0.61, mean reward: 7.6\n",
      "episode: 99/500, score: 5.0, e: 0.61, mean reward: 7.8\n",
      "episode: 100/500, score: 8.0, e: 0.61, mean reward: 7.6\n",
      "episode: 101/500, score: 6.0, e: 0.6, mean reward: 7.8\n",
      "episode: 102/500, score: 20.0, e: 0.59, mean reward: 7.6\n",
      "episode: 103/500, score: 8.0, e: 0.59, mean reward: 8.6\n",
      "episode: 104/500, score: 7.0, e: 0.58, mean reward: 7.5\n",
      "episode: 105/500, score: 7.0, e: 0.58, mean reward: 7.9\n",
      "episode: 106/500, score: 5.0, e: 0.58, mean reward: 7.8\n",
      "episode: 107/500, score: 5.0, e: 0.58, mean reward: 7.9\n",
      "episode: 108/500, score: 28.0, e: 0.56, mean reward: 7.8\n",
      "episode: 109/500, score: 6.0, e: 0.56, mean reward: 9.9\n",
      "episode: 110/500, score: 12.0, e: 0.55, mean reward: 10.0\n",
      "episode: 111/500, score: 20.0, e: 0.54, mean reward: 10.4\n",
      "episode: 112/500, score: 6.0, e: 0.54, mean reward: 11.8\n",
      "episode: 113/500, score: 15.0, e: 0.53, mean reward: 10.4\n",
      "episode: 114/500, score: 13.0, e: 0.52, mean reward: 11.1\n",
      "episode: 115/500, score: 7.0, e: 0.52, mean reward: 11.7\n",
      "episode: 116/500, score: 22.0, e: 0.51, mean reward: 11.7\n",
      "episode: 117/500, score: 6.0, e: 0.51, mean reward: 13.4\n",
      "episode: 118/500, score: 4.0, e: 0.51, mean reward: 13.5\n",
      "episode: 119/500, score: 15.0, e: 0.5, mean reward: 11.1\n",
      "episode: 120/500, score: 5.0, e: 0.5, mean reward: 12.0\n",
      "episode: 121/500, score: 10.0, e: 0.49, mean reward: 11.3\n",
      "episode: 122/500, score: 7.0, e: 0.49, mean reward: 10.3\n",
      "episode: 123/500, score: 17.0, e: 0.48, mean reward: 10.4\n",
      "episode: 124/500, score: 13.0, e: 0.48, mean reward: 10.6\n",
      "episode: 125/500, score: 10.0, e: 0.47, mean reward: 10.6\n",
      "episode: 126/500, score: 10.0, e: 0.47, mean reward: 10.9\n",
      "episode: 127/500, score: 3.0, e: 0.47, mean reward: 9.7\n",
      "episode: 128/500, score: 8.0, e: 0.46, mean reward: 9.4\n",
      "episode: 129/500, score: 14.0, e: 0.46, mean reward: 9.8\n",
      "episode: 130/500, score: 16.0, e: 0.45, mean reward: 9.7\n",
      "episode: 131/500, score: 12.0, e: 0.45, mean reward: 10.8\n",
      "episode: 132/500, score: 27.0, e: 0.43, mean reward: 11.0\n",
      "episode: 133/500, score: 9.0, e: 0.43, mean reward: 13.0\n",
      "episode: 134/500, score: 12.0, e: 0.43, mean reward: 12.2\n",
      "episode: 135/500, score: 17.0, e: 0.42, mean reward: 12.1\n",
      "episode: 136/500, score: 8.0, e: 0.42, mean reward: 12.8\n",
      "episode: 137/500, score: 18.0, e: 0.41, mean reward: 12.6\n",
      "episode: 138/500, score: 7.0, e: 0.41, mean reward: 14.1\n",
      "episode: 139/500, score: 6.0, e: 0.41, mean reward: 14.0\n",
      "episode: 140/500, score: 14.0, e: 0.4, mean reward: 13.2\n",
      "episode: 141/500, score: 45.0, e: 0.38, mean reward: 13.0\n",
      "episode: 142/500, score: 9.0, e: 0.38, mean reward: 16.3\n",
      "episode: 143/500, score: 7.0, e: 0.38, mean reward: 14.5\n",
      "episode: 144/500, score: 9.0, e: 0.37, mean reward: 14.3\n",
      "episode: 145/500, score: 21.0, e: 0.37, mean reward: 14.0\n",
      "episode: 146/500, score: 10.0, e: 0.36, mean reward: 14.4\n",
      "episode: 147/500, score: 8.0, e: 0.36, mean reward: 14.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 148/500, score: 12.0, e: 0.36, mean reward: 13.6\n",
      "episode: 149/500, score: 16.0, e: 0.35, mean reward: 14.1\n",
      "episode: 150/500, score: 6.0, e: 0.35, mean reward: 15.1\n",
      "episode: 151/500, score: 19.0, e: 0.34, mean reward: 14.3\n",
      "episode: 152/500, score: 3.0, e: 0.34, mean reward: 11.7\n",
      "episode: 153/500, score: 28.0, e: 0.33, mean reward: 11.1\n",
      "episode: 154/500, score: 21.0, e: 0.33, mean reward: 13.2\n",
      "episode: 155/500, score: 7.0, e: 0.33, mean reward: 14.4\n",
      "episode: 156/500, score: 32.0, e: 0.32, mean reward: 13.0\n",
      "episode: 157/500, score: 8.0, e: 0.31, mean reward: 15.2\n",
      "episode: 158/500, score: 4.0, e: 0.31, mean reward: 15.2\n",
      "episode: 159/500, score: 5.0, e: 0.31, mean reward: 14.4\n",
      "episode: 160/500, score: 7.0, e: 0.31, mean reward: 13.3\n",
      "episode: 161/500, score: 12.0, e: 0.31, mean reward: 13.4\n",
      "episode: 162/500, score: 13.0, e: 0.3, mean reward: 12.7\n",
      "episode: 163/500, score: 9.0, e: 0.3, mean reward: 13.7\n",
      "episode: 164/500, score: 13.0, e: 0.3, mean reward: 11.8\n",
      "episode: 165/500, score: 15.0, e: 0.29, mean reward: 11.0\n",
      "episode: 166/500, score: 8.0, e: 0.29, mean reward: 11.8\n",
      "episode: 167/500, score: 19.0, e: 0.28, mean reward: 9.4\n",
      "episode: 168/500, score: 14.0, e: 0.28, mean reward: 10.5\n",
      "episode: 169/500, score: 13.0, e: 0.28, mean reward: 11.5\n",
      "episode: 170/500, score: 3.0, e: 0.28, mean reward: 12.3\n",
      "episode: 171/500, score: 28.0, e: 0.27, mean reward: 11.9\n",
      "episode: 172/500, score: 10.0, e: 0.27, mean reward: 13.5\n",
      "episode: 173/500, score: 11.0, e: 0.26, mean reward: 13.2\n",
      "episode: 174/500, score: 13.0, e: 0.26, mean reward: 13.4\n",
      "episode: 175/500, score: 4.0, e: 0.26, mean reward: 13.4\n",
      "episode: 176/500, score: 4.0, e: 0.26, mean reward: 12.3\n",
      "episode: 177/500, score: 10.0, e: 0.26, mean reward: 11.9\n",
      "episode: 178/500, score: 8.0, e: 0.26, mean reward: 11.0\n",
      "episode: 179/500, score: 14.0, e: 0.25, mean reward: 10.4\n",
      "episode: 180/500, score: 13.0, e: 0.25, mean reward: 10.5\n",
      "episode: 181/500, score: 25.0, e: 0.24, mean reward: 11.5\n",
      "episode: 182/500, score: 52.0, e: 0.23, mean reward: 11.2\n",
      "episode: 183/500, score: 16.0, e: 0.23, mean reward: 15.4\n",
      "episode: 184/500, score: 24.0, e: 0.22, mean reward: 15.9\n",
      "episode: 185/500, score: 30.0, e: 0.22, mean reward: 17.0\n",
      "episode: 186/500, score: 43.0, e: 0.21, mean reward: 19.6\n",
      "episode: 187/500, score: 16.0, e: 0.2, mean reward: 23.5\n",
      "episode: 188/500, score: 20.0, e: 0.2, mean reward: 24.1\n",
      "episode: 189/500, score: 54.0, e: 0.19, mean reward: 25.3\n",
      "episode: 190/500, score: 53.0, e: 0.18, mean reward: 29.3\n",
      "episode: 191/500, score: 39.0, e: 0.17, mean reward: 33.3\n",
      "episode: 192/500, score: 17.0, e: 0.17, mean reward: 34.7\n",
      "episode: 193/500, score: 73.0, e: 0.16, mean reward: 31.2\n",
      "episode: 194/500, score: 45.0, e: 0.15, mean reward: 36.9\n",
      "episode: 195/500, score: 52.0, e: 0.14, mean reward: 39.0\n",
      "episode: 196/500, score: 53.0, e: 0.14, mean reward: 41.2\n",
      "episode: 197/500, score: 59.0, e: 0.13, mean reward: 42.2\n",
      "episode: 198/500, score: 53.0, e: 0.12, mean reward: 46.5\n",
      "episode: 199/500, score: 58.0, e: 0.12, mean reward: 49.8\n",
      "episode: 200/500, score: 77.0, e: 0.11, mean reward: 50.2\n",
      "episode: 201/500, score: 59.0, e: 0.1, mean reward: 52.6\n",
      "episode: 202/500, score: 81.0, e: 0.1, mean reward: 54.6\n",
      "episode: 203/500, score: 35.0, e: 0.1, mean reward: 61.0\n",
      "episode: 204/500, score: 73.0, e: 0.1, mean reward: 57.2\n",
      "episode: 205/500, score: 76.0, e: 0.1, mean reward: 60.0\n",
      "episode: 206/500, score: 97.0, e: 0.1, mean reward: 62.4\n",
      "episode: 207/500, score: 109.0, e: 0.1, mean reward: 66.8\n",
      "episode: 208/500, score: 127.0, e: 0.1, mean reward: 71.8\n",
      "episode: 209/500, score: 70.0, e: 0.1, mean reward: 79.2\n",
      "episode: 210/500, score: 62.0, e: 0.1, mean reward: 80.4\n",
      "episode: 211/500, score: 92.0, e: 0.1, mean reward: 78.9\n",
      "episode: 212/500, score: 31.0, e: 0.1, mean reward: 82.2\n",
      "episode: 213/500, score: 90.0, e: 0.1, mean reward: 77.2\n",
      "episode: 214/500, score: 88.0, e: 0.1, mean reward: 82.7\n",
      "episode: 215/500, score: 86.0, e: 0.1, mean reward: 84.2\n",
      "episode: 216/500, score: 84.0, e: 0.1, mean reward: 85.2\n",
      "episode: 217/500, score: 69.0, e: 0.1, mean reward: 83.9\n",
      "episode: 218/500, score: 96.0, e: 0.1, mean reward: 79.9\n",
      "episode: 219/500, score: 90.0, e: 0.1, mean reward: 76.8\n",
      "episode: 220/500, score: 36.0, e: 0.1, mean reward: 78.8\n",
      "episode: 221/500, score: 19.0, e: 0.1, mean reward: 76.2\n",
      "episode: 222/500, score: 107.0, e: 0.1, mean reward: 68.9\n",
      "episode: 223/500, score: 149.0, e: 0.1, mean reward: 76.5\n",
      "episode: 224/500, score: 154.0, e: 0.1, mean reward: 82.4\n",
      "episode: 225/500, score: 43.0, e: 0.1, mean reward: 89.0\n",
      "episode: 226/500, score: 121.0, e: 0.1, mean reward: 84.7\n",
      "episode: 227/500, score: 110.0, e: 0.1, mean reward: 88.4\n",
      "episode: 228/500, score: 91.0, e: 0.1, mean reward: 92.5\n",
      "episode: 229/500, score: 20.0, e: 0.1, mean reward: 92.0\n",
      "episode: 230/500, score: 31.0, e: 0.1, mean reward: 85.0\n",
      "episode: 231/500, score: 39.0, e: 0.1, mean reward: 84.5\n",
      "episode: 232/500, score: 135.0, e: 0.1, mean reward: 86.5\n",
      "episode: 233/500, score: 44.0, e: 0.1, mean reward: 89.3\n",
      "episode: 234/500, score: 111.0, e: 0.1, mean reward: 78.8\n",
      "episode: 235/500, score: 144.0, e: 0.1, mean reward: 74.5\n",
      "episode: 236/500, score: 94.0, e: 0.1, mean reward: 84.6\n",
      "episode: 237/500, score: 126.0, e: 0.1, mean reward: 81.9\n",
      "episode: 238/500, score: 79.0, e: 0.1, mean reward: 83.5\n",
      "episode: 239/500, score: 94.0, e: 0.1, mean reward: 82.3\n",
      "episode: 240/500, score: 20.0, e: 0.1, mean reward: 89.7\n",
      "episode: 241/500, score: 105.0, e: 0.1, mean reward: 88.6\n",
      "episode: 242/500, score: 8.0, e: 0.1, mean reward: 95.2\n",
      "episode: 243/500, score: 24.0, e: 0.1, mean reward: 82.5\n",
      "episode: 244/500, score: 59.0, e: 0.1, mean reward: 80.5\n",
      "episode: 245/500, score: 39.0, e: 0.1, mean reward: 75.3\n",
      "episode: 246/500, score: 145.0, e: 0.1, mean reward: 64.8\n",
      "episode: 247/500, score: 20.0, e: 0.1, mean reward: 69.9\n",
      "episode: 248/500, score: 38.0, e: 0.1, mean reward: 59.3\n",
      "episode: 249/500, score: 201.0, e: 0.1, mean reward: 55.2\n",
      "episode: 250/500, score: 63.0, e: 0.1, mean reward: 65.9\n",
      "episode: 251/500, score: 61.0, e: 0.1, mean reward: 70.2\n",
      "episode: 252/500, score: 93.0, e: 0.1, mean reward: 65.8\n",
      "episode: 253/500, score: 152.0, e: 0.1, mean reward: 74.3\n",
      "episode: 254/500, score: 56.0, e: 0.1, mean reward: 87.1\n",
      "episode: 255/500, score: 80.0, e: 0.1, mean reward: 86.8\n",
      "episode: 256/500, score: 244.0, e: 0.1, mean reward: 90.9\n",
      "episode: 257/500, score: 51.0, e: 0.1, mean reward: 100.8\n",
      "episode: 258/500, score: 116.0, e: 0.1, mean reward: 103.9\n",
      "episode: 259/500, score: 186.0, e: 0.1, mean reward: 111.7\n",
      "episode: 260/500, score: 500.0, e: 0.1, mean reward: 110.2\n",
      "episode: 261/500, score: 8.0, e: 0.1, mean reward: 153.9\n",
      "episode: 262/500, score: 229.0, e: 0.1, mean reward: 148.6\n",
      "episode: 263/500, score: 305.0, e: 0.1, mean reward: 162.2\n",
      "episode: 264/500, score: 170.0, e: 0.1, mean reward: 177.5\n",
      "episode: 265/500, score: 111.0, e: 0.1, mean reward: 188.9\n",
      "episode: 266/500, score: 129.0, e: 0.1, mean reward: 192.0\n",
      "episode: 267/500, score: 134.0, e: 0.1, mean reward: 180.5\n",
      "episode: 268/500, score: 209.0, e: 0.1, mean reward: 188.8\n",
      "episode: 269/500, score: 239.0, e: 0.1, mean reward: 198.1\n",
      "episode: 270/500, score: 119.0, e: 0.1, mean reward: 203.4\n",
      "episode: 271/500, score: 130.0, e: 0.1, mean reward: 165.3\n",
      "episode: 272/500, score: 102.0, e: 0.1, mean reward: 177.5\n",
      "episode: 273/500, score: 3.0, e: 0.1, mean reward: 164.8\n",
      "episode: 274/500, score: 289.0, e: 0.1, mean reward: 134.6\n",
      "episode: 275/500, score: 73.0, e: 0.1, mean reward: 146.5\n",
      "episode: 276/500, score: 20.0, e: 0.1, mean reward: 142.7\n",
      "episode: 277/500, score: 123.0, e: 0.1, mean reward: 131.8\n",
      "episode: 278/500, score: 13.0, e: 0.1, mean reward: 130.7\n",
      "episode: 279/500, score: 13.0, e: 0.1, mean reward: 111.1\n",
      "episode: 280/500, score: 26.0, e: 0.1, mean reward: 88.5\n",
      "episode: 281/500, score: 32.0, e: 0.1, mean reward: 79.2\n",
      "episode: 282/500, score: 10.0, e: 0.1, mean reward: 69.4\n",
      "episode: 283/500, score: 293.0, e: 0.1, mean reward: 60.2\n",
      "episode: 284/500, score: 92.0, e: 0.1, mean reward: 89.2\n",
      "episode: 285/500, score: 61.0, e: 0.1, mean reward: 69.5\n",
      "episode: 286/500, score: 175.0, e: 0.1, mean reward: 68.3\n",
      "episode: 287/500, score: 56.0, e: 0.1, mean reward: 83.8\n",
      "episode: 288/500, score: 92.0, e: 0.1, mean reward: 77.1\n",
      "episode: 289/500, score: 39.0, e: 0.1, mean reward: 85.0\n",
      "episode: 290/500, score: 92.0, e: 0.1, mean reward: 87.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 291/500, score: 61.0, e: 0.1, mean reward: 94.2\n",
      "episode: 292/500, score: 16.0, e: 0.1, mean reward: 97.1\n",
      "episode: 293/500, score: 220.0, e: 0.1, mean reward: 97.7\n",
      "episode: 294/500, score: 57.0, e: 0.1, mean reward: 90.4\n",
      "episode: 295/500, score: 97.0, e: 0.1, mean reward: 86.9\n",
      "episode: 296/500, score: 3.0, e: 0.1, mean reward: 90.5\n",
      "episode: 297/500, score: 6.0, e: 0.1, mean reward: 73.3\n",
      "episode: 298/500, score: 28.0, e: 0.1, mean reward: 68.3\n",
      "episode: 299/500, score: 248.0, e: 0.1, mean reward: 61.9\n",
      "episode: 300/500, score: 192.0, e: 0.1, mean reward: 82.8\n",
      "episode: 301/500, score: 8.0, e: 0.1, mean reward: 92.8\n",
      "episode: 302/500, score: 19.0, e: 0.1, mean reward: 87.5\n",
      "episode: 303/500, score: 109.0, e: 0.1, mean reward: 87.8\n",
      "episode: 304/500, score: 28.0, e: 0.1, mean reward: 76.7\n",
      "episode: 305/500, score: 36.0, e: 0.1, mean reward: 73.8\n",
      "episode: 306/500, score: 21.0, e: 0.1, mean reward: 67.7\n",
      "episode: 307/500, score: 114.0, e: 0.1, mean reward: 69.5\n",
      "episode: 308/500, score: 56.0, e: 0.1, mean reward: 80.3\n",
      "episode: 309/500, score: 116.0, e: 0.1, mean reward: 83.1\n",
      "episode: 310/500, score: 138.0, e: 0.1, mean reward: 69.9\n",
      "episode: 311/500, score: 59.0, e: 0.1, mean reward: 64.5\n",
      "episode: 312/500, score: 119.0, e: 0.1, mean reward: 69.6\n",
      "episode: 313/500, score: 72.0, e: 0.1, mean reward: 79.6\n",
      "episode: 314/500, score: 187.0, e: 0.1, mean reward: 75.9\n",
      "episode: 315/500, score: 7.0, e: 0.1, mean reward: 91.8\n",
      "episode: 316/500, score: 34.0, e: 0.1, mean reward: 88.9\n",
      "episode: 317/500, score: 206.0, e: 0.1, mean reward: 90.2\n",
      "episode: 318/500, score: 32.0, e: 0.1, mean reward: 99.4\n",
      "episode: 319/500, score: 142.0, e: 0.1, mean reward: 97.0\n",
      "episode: 320/500, score: 9.0, e: 0.1, mean reward: 99.6\n",
      "episode: 321/500, score: 285.0, e: 0.1, mean reward: 86.7\n",
      "episode: 322/500, score: 500.0, e: 0.1, mean reward: 109.3\n",
      "episode: 323/500, score: 13.0, e: 0.1, mean reward: 147.4\n",
      "episode: 324/500, score: 8.0, e: 0.1, mean reward: 141.5\n",
      "episode: 325/500, score: 97.0, e: 0.1, mean reward: 123.6\n",
      "episode: 326/500, score: 44.0, e: 0.1, mean reward: 132.6\n",
      "episode: 327/500, score: 54.0, e: 0.1, mean reward: 133.6\n",
      "episode: 328/500, score: 97.0, e: 0.1, mean reward: 118.4\n",
      "episode: 329/500, score: 62.0, e: 0.1, mean reward: 124.9\n",
      "episode: 330/500, score: 3.0, e: 0.1, mean reward: 116.9\n",
      "episode: 331/500, score: 57.0, e: 0.1, mean reward: 116.3\n",
      "episode: 332/500, score: 90.0, e: 0.1, mean reward: 93.5\n",
      "episode: 333/500, score: 51.0, e: 0.1, mean reward: 52.5\n",
      "episode: 334/500, score: 60.0, e: 0.1, mean reward: 56.3\n",
      "episode: 335/500, score: 105.0, e: 0.1, mean reward: 61.5\n",
      "episode: 336/500, score: 66.0, e: 0.1, mean reward: 62.3\n",
      "episode: 337/500, score: 33.0, e: 0.1, mean reward: 64.5\n",
      "episode: 338/500, score: 121.0, e: 0.1, mean reward: 62.4\n",
      "episode: 339/500, score: 8.0, e: 0.1, mean reward: 64.8\n",
      "episode: 340/500, score: 76.0, e: 0.1, mean reward: 59.4\n",
      "episode: 341/500, score: 124.0, e: 0.1, mean reward: 66.7\n",
      "episode: 342/500, score: 108.0, e: 0.1, mean reward: 73.4\n",
      "episode: 343/500, score: 155.0, e: 0.1, mean reward: 75.2\n",
      "episode: 344/500, score: 153.0, e: 0.1, mean reward: 85.6\n",
      "episode: 345/500, score: 50.0, e: 0.1, mean reward: 94.9\n",
      "episode: 346/500, score: 106.0, e: 0.1, mean reward: 89.4\n",
      "episode: 347/500, score: 43.0, e: 0.1, mean reward: 93.4\n",
      "episode: 348/500, score: 27.0, e: 0.1, mean reward: 94.4\n",
      "episode: 349/500, score: 12.0, e: 0.1, mean reward: 85.0\n",
      "episode: 350/500, score: 35.0, e: 0.1, mean reward: 85.4\n",
      "episode: 351/500, score: 270.0, e: 0.1, mean reward: 81.3\n",
      "episode: 352/500, score: 46.0, e: 0.1, mean reward: 95.9\n",
      "episode: 353/500, score: 48.0, e: 0.1, mean reward: 89.7\n",
      "episode: 354/500, score: 246.0, e: 0.1, mean reward: 79.0\n",
      "episode: 355/500, score: 204.0, e: 0.1, mean reward: 88.3\n",
      "episode: 356/500, score: 109.0, e: 0.1, mean reward: 103.7\n",
      "episode: 357/500, score: 108.0, e: 0.1, mean reward: 104.0\n",
      "episode: 358/500, score: 70.0, e: 0.1, mean reward: 110.5\n",
      "episode: 359/500, score: 102.0, e: 0.1, mean reward: 114.8\n",
      "episode: 360/500, score: 36.0, e: 0.1, mean reward: 123.8\n",
      "episode: 361/500, score: 26.0, e: 0.1, mean reward: 123.9\n",
      "episode: 362/500, score: 115.0, e: 0.1, mean reward: 99.5\n",
      "episode: 363/500, score: 195.0, e: 0.1, mean reward: 106.4\n",
      "episode: 364/500, score: 68.0, e: 0.1, mean reward: 121.1\n",
      "episode: 365/500, score: 10.0, e: 0.1, mean reward: 103.3\n",
      "episode: 366/500, score: 8.0, e: 0.1, mean reward: 83.9\n",
      "episode: 367/500, score: 30.0, e: 0.1, mean reward: 73.8\n",
      "episode: 368/500, score: 136.0, e: 0.1, mean reward: 66.0\n",
      "episode: 369/500, score: 166.0, e: 0.1, mean reward: 72.6\n",
      "episode: 370/500, score: 148.0, e: 0.1, mean reward: 79.0\n",
      "episode: 371/500, score: 146.0, e: 0.1, mean reward: 90.2\n",
      "episode: 372/500, score: 122.0, e: 0.1, mean reward: 102.2\n",
      "episode: 373/500, score: 83.0, e: 0.1, mean reward: 102.9\n",
      "episode: 374/500, score: 242.0, e: 0.1, mean reward: 91.7\n",
      "episode: 375/500, score: 29.0, e: 0.1, mean reward: 109.1\n",
      "episode: 376/500, score: 109.0, e: 0.1, mean reward: 111.0\n",
      "episode: 377/500, score: 24.0, e: 0.1, mean reward: 121.1\n",
      "episode: 378/500, score: 146.0, e: 0.1, mean reward: 120.5\n",
      "episode: 379/500, score: 6.0, e: 0.1, mean reward: 121.5\n",
      "episode: 380/500, score: 64.0, e: 0.1, mean reward: 105.5\n",
      "episode: 381/500, score: 354.0, e: 0.1, mean reward: 97.1\n",
      "episode: 382/500, score: 114.0, e: 0.1, mean reward: 117.9\n",
      "episode: 383/500, score: 17.0, e: 0.1, mean reward: 117.1\n",
      "episode: 384/500, score: 42.0, e: 0.1, mean reward: 110.5\n",
      "episode: 385/500, score: 79.0, e: 0.1, mean reward: 90.5\n",
      "episode: 386/500, score: 89.0, e: 0.1, mean reward: 95.5\n",
      "episode: 387/500, score: 18.0, e: 0.1, mean reward: 93.5\n",
      "episode: 388/500, score: 127.0, e: 0.1, mean reward: 92.9\n",
      "episode: 389/500, score: 45.0, e: 0.1, mean reward: 91.0\n",
      "episode: 390/500, score: 73.0, e: 0.1, mean reward: 94.9\n",
      "episode: 391/500, score: 53.0, e: 0.1, mean reward: 95.8\n",
      "episode: 392/500, score: 53.0, e: 0.1, mean reward: 65.7\n",
      "episode: 393/500, score: 7.0, e: 0.1, mean reward: 59.6\n",
      "episode: 394/500, score: 151.0, e: 0.1, mean reward: 58.6\n",
      "episode: 395/500, score: 224.0, e: 0.1, mean reward: 69.5\n",
      "episode: 396/500, score: 29.0, e: 0.1, mean reward: 84.0\n",
      "episode: 397/500, score: 97.0, e: 0.1, mean reward: 78.0\n",
      "episode: 398/500, score: 8.0, e: 0.1, mean reward: 85.9\n",
      "episode: 399/500, score: 260.0, e: 0.1, mean reward: 74.0\n",
      "episode: 400/500, score: 82.0, e: 0.1, mean reward: 95.5\n",
      "episode: 401/500, score: 238.0, e: 0.1, mean reward: 96.4\n",
      "episode: 402/500, score: 42.0, e: 0.1, mean reward: 114.9\n",
      "episode: 403/500, score: 5.0, e: 0.1, mean reward: 113.8\n",
      "episode: 404/500, score: 47.0, e: 0.1, mean reward: 113.6\n",
      "episode: 405/500, score: 19.0, e: 0.1, mean reward: 103.2\n",
      "episode: 406/500, score: 27.0, e: 0.1, mean reward: 82.7\n",
      "episode: 407/500, score: 178.0, e: 0.1, mean reward: 82.5\n",
      "episode: 408/500, score: 185.0, e: 0.1, mean reward: 90.6\n",
      "episode: 409/500, score: 194.0, e: 0.1, mean reward: 108.3\n",
      "episode: 410/500, score: 318.0, e: 0.1, mean reward: 101.7\n",
      "episode: 411/500, score: 109.0, e: 0.1, mean reward: 125.3\n",
      "episode: 412/500, score: 28.0, e: 0.1, mean reward: 112.4\n",
      "episode: 413/500, score: 11.0, e: 0.1, mean reward: 111.0\n",
      "episode: 414/500, score: 14.0, e: 0.1, mean reward: 111.6\n",
      "episode: 415/500, score: 70.0, e: 0.1, mean reward: 108.3\n",
      "episode: 416/500, score: 252.0, e: 0.1, mean reward: 113.4\n",
      "episode: 417/500, score: 142.0, e: 0.1, mean reward: 135.9\n",
      "episode: 418/500, score: 28.0, e: 0.1, mean reward: 132.3\n",
      "episode: 419/500, score: 35.0, e: 0.1, mean reward: 116.6\n",
      "episode: 420/500, score: 15.0, e: 0.1, mean reward: 100.7\n",
      "episode: 421/500, score: 63.0, e: 0.1, mean reward: 70.4\n",
      "episode: 422/500, score: 163.0, e: 0.1, mean reward: 65.8\n",
      "episode: 423/500, score: 16.0, e: 0.1, mean reward: 79.3\n",
      "episode: 424/500, score: 145.0, e: 0.1, mean reward: 79.8\n",
      "episode: 425/500, score: 74.0, e: 0.1, mean reward: 92.9\n",
      "episode: 426/500, score: 25.0, e: 0.1, mean reward: 93.3\n",
      "episode: 427/500, score: 71.0, e: 0.1, mean reward: 70.6\n",
      "episode: 428/500, score: 78.0, e: 0.1, mean reward: 63.5\n",
      "episode: 429/500, score: 115.0, e: 0.1, mean reward: 68.5\n",
      "episode: 430/500, score: 10.0, e: 0.1, mean reward: 76.5\n",
      "episode: 431/500, score: 23.0, e: 0.1, mean reward: 76.0\n",
      "episode: 432/500, score: 16.0, e: 0.1, mean reward: 72.0\n",
      "episode: 433/500, score: 116.0, e: 0.1, mean reward: 57.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 434/500, score: 28.0, e: 0.1, mean reward: 67.3\n",
      "episode: 435/500, score: 235.0, e: 0.1, mean reward: 55.6\n",
      "episode: 436/500, score: 89.0, e: 0.1, mean reward: 71.7\n",
      "episode: 437/500, score: 195.0, e: 0.1, mean reward: 78.1\n",
      "episode: 438/500, score: 81.0, e: 0.1, mean reward: 90.5\n",
      "episode: 439/500, score: 92.0, e: 0.1, mean reward: 90.8\n",
      "episode: 440/500, score: 88.0, e: 0.1, mean reward: 88.5\n",
      "episode: 441/500, score: 7.0, e: 0.1, mean reward: 96.3\n",
      "episode: 442/500, score: 14.0, e: 0.1, mean reward: 94.7\n",
      "episode: 443/500, score: 121.0, e: 0.1, mean reward: 94.5\n",
      "episode: 444/500, score: 45.0, e: 0.1, mean reward: 95.0\n",
      "episode: 445/500, score: 57.0, e: 0.1, mean reward: 96.7\n",
      "episode: 446/500, score: 61.0, e: 0.1, mean reward: 78.9\n",
      "episode: 447/500, score: 29.0, e: 0.1, mean reward: 76.1\n",
      "episode: 448/500, score: 53.0, e: 0.1, mean reward: 59.5\n",
      "episode: 449/500, score: 264.0, e: 0.1, mean reward: 56.7\n",
      "episode: 450/500, score: 133.0, e: 0.1, mean reward: 73.9\n",
      "episode: 451/500, score: 108.0, e: 0.1, mean reward: 78.4\n",
      "episode: 452/500, score: 11.0, e: 0.1, mean reward: 88.5\n",
      "episode: 453/500, score: 72.0, e: 0.1, mean reward: 88.2\n",
      "episode: 454/500, score: 75.0, e: 0.1, mean reward: 83.3\n",
      "episode: 455/500, score: 37.0, e: 0.1, mean reward: 86.3\n",
      "episode: 456/500, score: 27.0, e: 0.1, mean reward: 84.3\n",
      "episode: 457/500, score: 289.0, e: 0.1, mean reward: 80.9\n",
      "episode: 458/500, score: 32.0, e: 0.1, mean reward: 106.9\n",
      "episode: 459/500, score: 19.0, e: 0.1, mean reward: 104.8\n",
      "episode: 460/500, score: 69.0, e: 0.1, mean reward: 80.3\n",
      "episode: 461/500, score: 180.0, e: 0.1, mean reward: 73.9\n",
      "episode: 462/500, score: 67.0, e: 0.1, mean reward: 81.1\n",
      "episode: 463/500, score: 69.0, e: 0.1, mean reward: 86.7\n",
      "episode: 464/500, score: 195.0, e: 0.1, mean reward: 86.4\n",
      "episode: 465/500, score: 180.0, e: 0.1, mean reward: 98.4\n",
      "episode: 466/500, score: 65.0, e: 0.1, mean reward: 112.7\n",
      "episode: 467/500, score: 40.0, e: 0.1, mean reward: 116.5\n",
      "episode: 468/500, score: 205.0, e: 0.1, mean reward: 91.6\n",
      "episode: 469/500, score: 89.0, e: 0.1, mean reward: 108.9\n",
      "episode: 470/500, score: 141.0, e: 0.1, mean reward: 115.9\n",
      "episode: 471/500, score: 133.0, e: 0.1, mean reward: 123.1\n",
      "episode: 472/500, score: 54.0, e: 0.1, mean reward: 118.4\n",
      "episode: 473/500, score: 160.0, e: 0.1, mean reward: 117.1\n",
      "episode: 474/500, score: 32.0, e: 0.1, mean reward: 126.2\n",
      "episode: 475/500, score: 149.0, e: 0.1, mean reward: 109.9\n",
      "episode: 476/500, score: 75.0, e: 0.1, mean reward: 106.8\n",
      "episode: 477/500, score: 51.0, e: 0.1, mean reward: 107.8\n",
      "episode: 478/500, score: 70.0, e: 0.1, mean reward: 108.9\n",
      "episode: 479/500, score: 88.0, e: 0.1, mean reward: 95.4\n",
      "episode: 480/500, score: 9.0, e: 0.1, mean reward: 95.3\n",
      "episode: 481/500, score: 30.0, e: 0.1, mean reward: 82.1\n",
      "episode: 482/500, score: 129.0, e: 0.1, mean reward: 71.8\n",
      "episode: 483/500, score: 116.0, e: 0.1, mean reward: 79.3\n",
      "episode: 484/500, score: 29.0, e: 0.1, mean reward: 74.9\n",
      "episode: 485/500, score: 29.0, e: 0.1, mean reward: 74.6\n",
      "episode: 486/500, score: 84.0, e: 0.1, mean reward: 62.6\n",
      "episode: 487/500, score: 159.0, e: 0.1, mean reward: 63.5\n",
      "episode: 488/500, score: 20.0, e: 0.1, mean reward: 74.3\n",
      "episode: 489/500, score: 62.0, e: 0.1, mean reward: 69.3\n",
      "episode: 490/500, score: 137.0, e: 0.1, mean reward: 66.7\n",
      "episode: 491/500, score: 85.0, e: 0.1, mean reward: 79.5\n",
      "episode: 492/500, score: 3.0, e: 0.1, mean reward: 85.0\n",
      "episode: 493/500, score: 77.0, e: 0.1, mean reward: 72.4\n",
      "episode: 494/500, score: 157.0, e: 0.1, mean reward: 68.5\n",
      "episode: 495/500, score: 86.0, e: 0.1, mean reward: 81.3\n",
      "episode: 496/500, score: 70.0, e: 0.1, mean reward: 87.0\n",
      "episode: 497/500, score: 161.0, e: 0.1, mean reward: 85.6\n",
      "episode: 498/500, score: 17.0, e: 0.1, mean reward: 85.8\n",
      "episode: 499/500, score: 3.0, e: 0.1, mean reward: 85.5\n"
     ]
    }
   ],
   "source": [
    "# N_sensors = 20\n",
    "# env = gym.make('Car-v1', N_cars=1, N_sensors=N_sensors, sensor_angle=2*np.pi, N_obs=0, Ts=0.1)\n",
    "env = gym.make('InvertedPendulum-v2')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.shape[0]\n",
    "max_action = env.action_space.high\n",
    "\n",
    "# print(env.observation_space.shape, env.action_space.shape)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "agent = DDPG(state_size, action_size, max_action=max_action, eps=1., gamma=0.95, lr_c=1e-3, lr_a=1e-4,\n",
    "             H=128, eps_min=0.1, sigma=0.3, mem_size=100000, name=\"car_new_filtered\")\n",
    "\n",
    "EPISODES = 500\n",
    "max_ep = 500\n",
    "done = False\n",
    "batch_size = 32\n",
    "last_max_rew = 3000\n",
    "total_rewards = []\n",
    "mean_rewards = []\n",
    "\n",
    "try:\n",
    "    for e in range(EPISODES):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        ep_reward = 0.\n",
    "\n",
    "        for time in range(max_ep):\n",
    "    #         img = env.render(render_measures=True)\n",
    "    #         cv2.imshow('', img)\n",
    "    #         cv2.waitKey(1)\n",
    "            env.render()\n",
    "\n",
    "            action = agent.act(state)\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            ep_reward += reward\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if not done:\n",
    "                done = time >= max_ep-1\n",
    "\n",
    "            if done:\n",
    "                mean_rewards.append(np.mean(total_rewards[-10:]))\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}, mean reward: {}\"\n",
    "                      .format(e, EPISODES, ep_reward, agent.epsilon, mean_rewards[-1]))\n",
    "                break\n",
    "\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "\n",
    "        if e % 1 == 0:\n",
    "            agent.update_target(0.9)\n",
    "\n",
    "        total_rewards.append(ep_reward)\n",
    "\n",
    "        if (ep_reward > last_max_rew or ep_reward > 3000):\n",
    "            last_max_rew = ep_reward\n",
    "            agent.save(\"car-ddpg\" + str(e))\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75bee87668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.plot(total_rewards)\n",
    "plt.plot(mean_rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
